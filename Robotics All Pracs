roboprac13

Practical 3 ------------------------------------------------------

Aim: Write a python code to test motors

(CODE - Create firmware - Raspberry Pi)

Source Code:

import RPi.GPIO as GPIO import time
GPIO.setmode(GPIO.BOARD)
GPIO.setwarnings(False)button=12
DC_motor_a=7
DC_motor_b=11
GPIO.setup(DC_motor_a,GPIO.OUT)
GPIO.setup(DC_motor_b,GPIO.OUT)
GPIO.setup(button,GPIO.IN,pull_up_down=GPIO.PUD_UP)
while(1):
	if GPIO.input(button)==GPIO.LOW:
		GPIO.output(DC_motor_a,GPIO.HIGH)
		GPIO.output(DC_motor_b,GPIO.LOW)
		time.sleep(0.1)
	else: 
	GPIO.output(DC_motor_a,GPIO.LOW)
	GPIO.output(DC_motor_b,GPIO.HIGH)
	time.sleep(0.1)


Practical 4 ------------------------------------------------------

Aim: Write a script to follow a predetermined path.

Components: Raspberry pi Board3, L293D, Simple DC Motor, Button

---Readymade not available---
(CODE - Create firmware - Raspberry Pi)

Raspberry Pi, Active DC motor, Active L293D
Source Code>Right click RPI3(U1)>Add Peripheral>Category>Breakout Peripherals>Momentary Action Push button

L293D Connection: Pin 3 to Motor top pin, Pin 6 to Motor bottom pin, Pin 8 & 16 connect together with Power VCC, Pin GND to Ground, Pin 2 to GPIO 4, Pin 7 to GPIO 17

Source Code:

import RPi.GPIO as GPIO import
time
GPIO.setmode(GPIO.BOARD)
GPIO.setwarnings(False)button=12
DC_motor_a=7
DC_motor_b=11
GPIO.setup(DC_motor_a,GPIO.OUT)
GPIO.setup(DC_motor_b,GPIO.OUT)
GPIO.setup(button,GPIO.IN,pull_up_down=GPIO.PUD_UP)
while(1):
	if GPIO.input(button)==GPIO.LOW:
		GPIO.output(DC_motor_a,GPIO.HIGH)
		GPIO.output(DC_motor_b,GPIO.LOW)
		time.sleep(0.1)
	else:
	GPIO.output(DC_motor_a,GPIO.LOW)
	GPIO.output(DC_motor_b,GPIO.HIGH)
	time.sleep(0.1)


Practical 5 ------------------------------------------------------

Aim: Develop Python code for testing the sensors. (Tinkercad)

Components: PIR Sensor, Resistor, Piezo, Arduino Uno R3, LED RGB

Step I. Place the components in TinkerCad.

PIR Sensor:
Left pin to Pin 2 of Arduino (Digitial PWM) --- Middle pin to 5V (Power) --- Right pin to GND (Power)

Piezo:
Left positive pin to Resistor terminal 2 (top), Resistor terminal 1 (bottom) to GND (Digital PWM)
Right negative pin to Pin 12 of Arduino (Digital PWM)

LED RGB:
2nd leg to Resistor terminal 2 (top), Resistor teminal 1 (bottom) to GND (Digital PWM)
4th leg to Pin 13 of Arduino (Digital PWM)

Step II. Type the following code

int pirsensor = 0;void
setup()
{
pinMode(2, INPUT);
pinMode(12, OUTPUT);
pinMode(13, OUTPUT);
}
void loop()
{
pirsensor = digitalRead(2);if
(pirsensor == HIGH)
{
digitalWrite(13,HIGH);
tone(12,500,500);
}
digitalWrite(13,LOW);
}


Practical 6 ------------------------------------------------------

Aim: Add the sensors to the robot object and develop the line follower behaviour code

Components: Ardinuo, Button, Zumo robot, Proteus 8.13 simulator

Proteus>Open Sample>Zumo Line Follower

(FLOWCHART - Create flowchart - Arduino UNO)

Arduino Uno, Zumo Robot
Visual Designer>Right click Arduino Uno(U1)>Add Peripheral>Category>Motor Control>Arduino Zumo Robot

Source Code:

#pragma GCC push_options
#pragma GCC optimize ("Os")
#include <core.h> // Required by cpu#include <cpu.h>
#include <TimerOne.h>
#include <L3G.h> // Required by Z1:DRIVE #include
<LSM303.h> // Required by Z1:DRIVE#include <Wire.h>
// Required by Z1:DRIVE #include <Servo.h> // Required
by Z1:DRIVE#include <Zumo.h>
#pragma GCC pop_options
// Peripheral ConstructorsCPU
&cpu = Cpu;
TimerOne &timer1 = Timer1;
DRIVE Z1_DRIVE = DRIVE (8, 10, 7, 9);
LINESENSOR Z1_LINESENSOR = LINESENSOR (4, A3, 11, A0, A2, 5, 2);COMPASS
Z1_COMPASS = COMPASS ();
GYRO Z1_GYRO = GYRO ();
void peripheral_setup ()
{
Z1_DRIVE.begin ();
Z1_LINESENSOR.begin ();
Z1_COMPASS.begin ();
Z1_GYRO.begin ();

}
void peripheral_loop() {
}
//---CONFIG_END--- //
Flowchart Variables long
var_linePosition;long
var_error;
long var_lastError;
long var_speedDifference;long
var_leftSpeed;
long var_rightSpeed;long
var_maxSpeed; float
var_magX; float
var_magY; float
var_magZ;
// Flowchart Routinesvoid
chart_SETUP() {
var_lastError=0,var_maxSpeed=255;
}
void chart_LOOP() { var_linePosition=Z1_LINESENSOR.readLinePos();

var_error=var_linePosition-2500; var_speedDifference=var_error/4+6*(var_error-
var_lastError); var_lastError=var_error;

var_leftSpeed=var_maxSpeed+var_speedDifference,var_rightSpeed=var_maxSpeedvar_speedDifference;
chart_boundSpeeds(); Z1_DRIVE.drive(1,1,var_leftSpeed);
Z1_DRIVE.drive(2,1,var_rightSpeed);
}
void chart_boundSpeeds() {
if(var_leftSpeed<0) {
var_leftSpeed=0;
}
else {
if(var_rightSpeed<0) {
var_rightSpeed=0;
} else { if(var_leftSpeed>var_maxSpeed) {
var_leftSpeed=var_maxSpeed;
} else { if(var_rightSpeed>var_maxSpeed) {
var_rightSpeed=var_maxSpeed;
}
}
}
}

}

// Entry Points and Interrupt Handlers
void setup () 
{ peripheral_setup(); chart_SETUP(); }void loop () {
peripheral_loop(); chart_LOOP(); }


Practical 7 ------------------------------------------------------

Aim: Using Light strip to develop and debug the line follower robot

Components: Raspberry pi, strip RGB LED Circuit

Proteus>Open Sample>Raspberry Pi TriColour LED

(CODE - Create firmware - Raspberry Pi)

Source Code>Right click RPI3(U1)>Add Peripheral>Category>Breakout Peripherals>RGB Common Anode LED

Source code in python:

from goto import with_gotofrom
stddef import * import var
import pio import
resource
from datetime import datetime
# Peripheral Configuration Code (Do Not Edit)#---
CONFIG_BEGIN---
import cpu import
FileStoreimport timer
import VFP import
Generic
def peripheral_setup () :
# Peripheral Constructors pio.cpu=cpu.CPU ()
pio.storage=FileStore.FileStore ()
pio.timer=timer.Timer ()
pio.server=VFP.VfpServer ()
pio.RGBLED1=Generic.RgbLedCa (pio.GPIO19, pio.GPIO20, pio.GPIO26)pio.storage.begin ()
pio.server.begin (0)


# Install interrupt handlersdef
peripheral_loop () :
pio.timer.poll ()
pio.server.poll ()
#---CONFIG_END---
def variables_setup () :
# Flowchart Variablespass
# Flowchart Routines
@with_goto
def chart_SETUP () : return
@with_goto
def chart_LOOP () :
pio.RGBLED1.set (True, True, True)sleep((500)*0.001)
pio.RGBLED1.set (True, False, False)sleep((500)*0.001)
pio.RGBLED1.set (True, True, False)
sleep((500)*0.001)
pio.RGBLED1.set (False, True, False)sleep((500)*0.001)
pio.RGBLED1.set (False, True, True)
sleep((500)*0.001)
pio.RGBLED1.set (False, False, True)sleep((500)*0.001)
pio.RGBLED1.set (True, False, True)
sleep((500)*0.001)
pio.RGBLED1.set (False, False, False)sleep((500)*0.001)
return
# Main functiondef
main () :
# Setup
variables_setup ()
peripheral_setup ()
chart_SETUP ()
# Infinite loop
while True :
peripheral_loop ()
chart_LOOP ()
# Command line execution
if name == ' main ' :main()


Practical 8 ------------------------------------------------------

Aim: Create an obstacle avoidance behaviour for robot and test it.

Components: Arduino uno, Zumo robot

Proteus>Open Sample> Virtual turtle - Follow and Avoid

(FLOWCHART - Create flowchart - Arduino UNO)

Arduino Uno, Zumo Robot
Visual Designer>Right click Arduino Uno(U1)>Add Peripheral>Category>Motor Control>Arduino Zumo Robot

Source code:

//---CONFIG_BEGIN---
#pragma GCC push_options
#pragma GCC optimize ("Os")
#include <core.h> // Required by cpu#include <cpu.h>
#include <TimerOne.h>
#include <Servo.h> // Required by T1: DRIVE#include
<Turtle.h>

#pragma GCC pop_options
// Peripheral ConstructorsCPU
&cpu = Cpu;
TimerOne &timer1 = Timer1;
TurtleDrive T1_DRIVE = TurtleDrive (2, 4, 3, 6, 7, 5);
TurtleSonarHead T1_SH = TurtleSonarHead (8, 9, 10); TurtleLineHunter T1_LH =
TurtleLineHunter (11, 12, A0);
void peripheral_setup () {
T1_DRIVE.begin ();
T1_SH.begin (); T1_LH.begin ();
}
void peripheral_loop() {
}
//---CONFIG_END--- //
Flowchart Variableslong
var_speed; long var_dir;
long var_count; long
var_range; long
var_fast; long
var_slow; long
var_tstart;long
var_tstop;
// Flowchart Routinesvoid
chart_SETUP() {
var_speed=180,var_range=10,var_dir=0;
T1_SH.setAngle(0); T1_SH.setRange(25);
T1_DRIVE.forwards(var_speed);
}
void chart_LOOP() {
if(!(T1_LH(0,0,0))) {
if(T1_LH(1,1,1)) {
chart_Correct();
} else { if(T1_LH(0,1,1))
{
T1_DRIVE.drive(1,1,5*var_speed/4);
T1_DRIVE.drive(2,1,var_speed/2); var_dir=10;
chart_Avoid();
} else { if(T1_LH(0,0,1))
{
T1_DRIVE.drive(1,1,5*var_speed/4);
T1_DRIVE.drive(2,0,var_speed/5);
var_dir=30;

} else { if(T1_LH(1,1,0))
{
T1_DRIVE.drive(2,1,5*var_speed/4);
T1_DRIVE.drive(1,1,var_speed/2); var_dir=-
10;
chart_Avoid();
} else { if(T1_LH(1,0,0))
{
T1_DRIVE.drive(2,1,5*var_speed/4);
T1_DRIVE.drive(1,0,var_speed/5); var_dir=-
30;
} else {
if(T1_LH(-1,1,-1)) {
T1_DRIVE.forwards(var_speed);
var_dir=0;
chart_Avoid();
}
}
}
}
}
}
}
}
void chart_Correct() {
var_count=0;
l3:;
if(var_dir>0) { T1_DRIVE.drive(2,1,var_speed);
T1_DRIVE.drive(1,0,var_speed/3);
} else { if(var_dir<0) {
T1_DRIVE.drive(1,1,var_speed);
T1_DRIVE.drive(2,0,var_speed/3);
}
}
delay(1);
var_count=var_count+1;
if(var_count<1000) {
if (T1_LH(1,1,1)) goto l3;
} else {
T1_DRIVE.stop();
var_dir=0;
}
}
void chart_Avoid() { if(T1_SH(var_range,0)) {
T1_DRIVE.backwards(2*var_speed/3);delay(250);

T1_DRIVE.turn(80);
do {
delay(5);
} while ((!(T1_SH(1.5*var_range,0))) == false);T1_DRIVE.stop();
delay(500);
T1_DRIVE.turn(80);
var_tstart=cpu.millis();
while (!(T1_SH(1.5*var_range,0))) {
}

var_tstop=cpu.millis(); var_count=(var_tstop-
var_tstart)/10;T1_DRIVE.stop();

delay(500);
T1_DRIVE.turn(-80);
while (var_count>0) {
var_count=var_count-1;
delay(5);
}
T1_DRIVE.backwards(2*var_speed/3);delay(300);
T1_DRIVE.forwards(var_speed/2);
}
}
// Entry Points and Interrupt Handlers
void setup () { peripheral_setup(); chart_SETUP(); }void loop () {
peripheral_loop(); chart_LOOP();


Practical 9 ------------------------------------------------------

Aim: Detect faces with HAAR cascades

(Google Colab)

Code: 

#!pip install opencv_python import
cv2
#reading the image
img = cv2.imread("face.jpg")
#converting image to grayscale
gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
#Loading the required haar-cascade.xml classifier file haar_cascade =
cv2.CascadeClassifier(cv2.data.haarcascades +"haarcascade_frontalface_default.xml")
eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades +"haarcascade_eye.xml")

faces_rect = haar_cascade.detectMultiScale(gray_img, 1.3, 5)eyes =
eye_cascade.detectMultiScale(gray_img)

for(x, y, w ,h) in faces_rect:
cv2.rectangle(img, (x,y), (x+w, y+h), (0,255,0), 1)for(ex, ey, ew ,eh) in eyes:
cv2.rectangle(img, (ex,ey), (ex+ew, ey+eh), (0,255,0), 1)

cv2.imshow('Detected faces', img)
cv2.waitKey(0)


Practical 10 ------------------------------------------------------

Aim: Using the robot to display its camera as a web app on a phone or desktop and then use camera to
drive smart colour and face tracking behaviours.

Components: Proteus Simulator 8.9 and above, Lcd TFT, Button, Raspberry pi camera

ILI9341 320x240 Graphical TFT
Source Code>Right click RPI3(U1)>Add Peripheral>Category>Breakout Peripherals>Momentary Action Push button
Source Code>Right click RPI3(U1)>Add Peripheral>Category>Camera>Raspberry pi camera module


Proteus>Open Sample>TFT Display with Camera

(FLOWCHART - Create flowchart - Raspberry Pi)


