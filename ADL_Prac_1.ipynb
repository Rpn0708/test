{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOInmbRRwt9wOydKjPuifks",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rpn0708/test/blob/main/ADL_Prac_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "B2DvOmv57r-7"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Iris dataset\n",
        "iris = load_iris()"
      ],
      "metadata": {
        "id": "x7CLhZcl77Uo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get features and output\n",
        "X = iris.data\n",
        "y = iris.target"
      ],
      "metadata": {
        "id": "TfOtPCPw78i_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode labels\n",
        "lb = LabelBinarizer()\n",
        "y = lb.fit_transform(y)"
      ],
      "metadata": {
        "id": "2tMHrARs7-ov"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "znfXljoj8A4o"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model architecture\n",
        "model = tf.keras.Sequential([\n",
        "tf.keras.layers.Dense(16, input_shape=(4,), activation='relu'),\n",
        "tf.keras.layers.Dense(8, activation='relu'),\n",
        "tf.keras.layers.Dense(3, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "T072BYmL8IPX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model with different optimizers\n",
        "optimizers = ['sgd', 'adam', 'rmsprop']\n",
        "for optimizer in optimizers:\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "S9hLwsPW8QpX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, verbose=0)"
      ],
      "metadata": {
        "id": "Xi9vL0pS8hE5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Optimizer:', optimizer)\n",
        "print('Test loss:', loss)\n",
        "print('Test accuracy:', accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qfYH95I8mtJ",
        "outputId": "92b6542d-d72a-4027-8aba-1d869db04408"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimizer: rmsprop\n",
            "Test loss: 0.6525971293449402\n",
            "Test accuracy: 0.8999999761581421\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer"
      ],
      "metadata": {
        "id": "R3pYCB608qup"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Iris dataset\n",
        "iris = load_iris() # Loading Iris dataset into a variable.\n",
        "X = iris.data # Features of the dataset.\n",
        "y = iris.target # Class labels of the dataset."
      ],
      "metadata": {
        "id": "1w-uhsc48w5p"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode labels\n",
        "lb = LabelBinarizer() # Creating an instance of LabelBinarizer class for one-hot encoding.\n",
        "y = lb.fit_transform(y) # One-hot encoding the class labels."
      ],
      "metadata": {
        "id": "CnhatVjv8z75"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# Splitting the dataset into training and testing sets with a test size of 20%."
      ],
      "metadata": {
        "id": "Q-SD7Rqz82m0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model architecture\n",
        "model = tf.keras.Sequential([\n",
        "\n",
        "  tf.keras.layers.Dense(16, input_shape=(4,), activation='relu'), # First hidden layer with 16 neurons and input shape of 4 features. ReLU activation function is used.\n",
        "  tf.keras.layers.Dense(8, activation='relu'), # Second hidden layer with 8 neurons. ReLU activation function is used.\n",
        "  tf.keras.layers.Dense(3, activation='softmax') # Output layer with 3 neurons for 3 classes. Softmax activation function is used for multiclass classification task.\n",
        "])"
      ],
      "metadata": {
        "id": "ILIans3i8-WS"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model with different optimizers\n",
        "optimizers = ['sgd', 'adam', 'rmsprop'] # List of optimizers to be used for training the model.\n",
        "for optimizer in optimizers: # Looping over each optimizer.\n",
        "# Compiling the model with 'categorical_crossentropy' as the loss function, the current optimizer and accuracy as the metric to be calculated.\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Xoib7zfg9OZ7"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, verbose=0) # Training the model for 50 epochs with verbose=0 to suppress the output."
      ],
      "metadata": {
        "id": "UwTXKnzz9s7j"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0) # Evaluating the model on the test set and calculating the loss and accuracy.\n",
        "print('Optimizer:', optimizer) # Printing the optimizer name.\n",
        "print('Test loss:', loss) # Printing the loss value on the test set.\n",
        "print('Test accuracy:', accuracy) # Printing the accuracy value on the test set."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEKSbNtN9xks",
        "outputId": "d078b904-c7df-4a45-a5f4-53eafbcf9fee"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimizer: rmsprop\n",
            "Test loss: 0.2923169732093811\n",
            "Test accuracy: 0.9666666388511658\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Allow user to input values for the flower attributes\n",
        "print('\\nInput values for the flower attributes:')\n",
        "sepal_length = float(input('Sepal length (cm): '))\n",
        "sepal_width = float(input('Sepal width (cm): '))\n",
        "petal_length = float(input('Petal length (cm): '))\n",
        "petal_width = float(input('Petal width (cm): '))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2GuLa0094xc",
        "outputId": "c640d822-192d-4c25-cbcb-063990fc6e94"
      },
      "execution_count": 23,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Input values for the flower attributes:\n",
            "Sepal length (cm): 10\n",
            "Sepal width (cm): 20\n",
            "Petal length (cm): 50\n",
            "Petal width (cm): 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict class of flower based on input values\n",
        "input_values = np.array([[sepal_length, sepal_width, petal_length, petal_width]])\n",
        "prediction = model.predict(input_values)\n",
        "predicted_class = np.argmax(prediction)\n",
        "class_names = iris.target_names\n",
        "print('\\nPredicted class: ', class_names[predicted_class])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgG6mJQc-FBM",
        "outputId": "b6f9dfc3-c77c-43ac-ba2d-096cb69fb042"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 147ms/step\n",
            "\n",
            "Predicted class:  virginica\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "# Load Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# One-hot encode labels\n",
        "lb = LabelBinarizer()\n",
        "y = lb.fit_transform(y)\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define model architecture\n",
        "model = tf.keras.Sequential([\n",
        "tf.keras.layers.Dense(16, input_shape=(4,), activation='relu'),\n",
        "tf.keras.layers.Dense(8, activation='relu'),\n",
        "tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "# Define dictionary of optimizers\n",
        "optimizers = {\n",
        "'sgd': tf.keras.optimizers.SGD(),\n",
        "'adam': tf.keras.optimizers.Adam(),\n",
        "'rmsprop': tf.keras.optimizers.RMSprop()\n",
        "}\n",
        "\n",
        "# Compile model with different optimizers\n",
        "for optimizer_name, optimizer in optimizers.items():\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, verbose=0)\n",
        "\n",
        "# Evaluate model\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Optimizer:', optimizer_name)\n",
        "print('Test loss:', loss)\n",
        "print('Test accuracy:', accuracy)\n",
        "\n",
        "# Estimate memory requirement\n",
        "size_in_bytes = model.count_params() * 4 # each parameter is a 32-bit float\n",
        "size_in_mb = size_in_bytes / (1024 * 1024)\n",
        "print(f'Memory requirement: {size_in_mb:.2f} MB')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1IYXBCk-JLX",
        "outputId": "2fd26733-fe0d-463c-e583-119116dee6ca"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimizer: rmsprop\n",
            "Test loss: 0.6445446610450745\n",
            "Test accuracy: 0.8666666746139526\n",
            "Memory requirement: 0.00 MB\n"
          ]
        }
      ]
    }
  ]
}